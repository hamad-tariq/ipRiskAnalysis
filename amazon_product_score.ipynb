{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"total_score\": 95,\n",
      "  \"individual_scores\": {\n",
      "    \"large_drop_2days\": 45,\n",
      "    \"extra_large_drop_2days\": 85\n",
      "  },\n",
      "  \"risk_factors\": [\n",
      "    {\n",
      "      \"factor\": \"large_drop_2days\",\n",
      "      \"severity\": 45\n",
      "    },\n",
      "    {\n",
      "      \"factor\": \"extra_large_drop_2days\",\n",
      "      \"severity\": 85\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Replace with your actual Keepa API key\n",
    "API_KEY = '1o6o8o0bd5ko9o6o635rs85jqj0no7g1upls93u8tbtt83sdt5gak24m593s6967'\n",
    "API_URL = 'https://api.keepa.com/product?key={}&domain=1&asin={}'\n",
    "\n",
    "def fetch_keepa_data(asin):\n",
    "    response = requests.get(API_URL.format(API_KEY, asin))\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"Failed to fetch data from Keepa API, status code: {response.status_code}\")\n",
    "    return response.json()\n",
    "\n",
    "def process_price_history(product_data):\n",
    "    csv_data = product_data.get('csv', [])\n",
    "    offer_price_data = csv_data[3] if len(csv_data) > 3 and csv_data[3] is not None else []\n",
    "    if not offer_price_data:\n",
    "        raise ValueError(\"Offer price data is missing or not at the expected index.\")\n",
    "    \n",
    "    base_date = datetime(2011, 1, 1)\n",
    "    offer_price_dates = [base_date + timedelta(minutes=30 * i) for i in range(0, len(offer_price_data), 2)]\n",
    "    offer_price_values = [offer_price_data[i] for i in range(1, len(offer_price_data), 2)]\n",
    "    \n",
    "    df_prices = pd.DataFrame({\n",
    "        'Date': offer_price_dates,\n",
    "        'OfferPrice': offer_price_values\n",
    "    })\n",
    "    return df_prices\n",
    "\n",
    "def detect_castle_top_pattern(series, window=336):\n",
    "    if len(series) < window:\n",
    "        return [0] * len(series)\n",
    "    pattern_detected = [0] * window\n",
    "    for i in range(window, len(series) - window):\n",
    "        is_castle_top = all(series[j] > series[j - 1] and series[j] > series[j + 1] for j in range(i - window // 2, i + window // 2, 2))\n",
    "        pattern_detected.append(int(is_castle_top))\n",
    "    pattern_detected.extend([0] * (len(series) - len(pattern_detected)))\n",
    "    return pattern_detected\n",
    "\n",
    "def detect_flat_lines(series, min_length=960, max_length=1440):\n",
    "    if len(series) < min_length:\n",
    "        return [0] * len(series)\n",
    "    flat_line = [0] * len(series)\n",
    "    count = 0\n",
    "    for i in range(1, len(series)):\n",
    "        if series[i] == series[i-1]:\n",
    "            count += 1\n",
    "        else:\n",
    "            if min_length <= count <= max_length:\n",
    "                for j in range(i - count, i):\n",
    "                    flat_line[j] = 1\n",
    "            count = 0\n",
    "    return flat_line\n",
    "\n",
    "def analyze_data(asin):\n",
    "    keepa_data = fetch_keepa_data(asin)\n",
    "    if 'products' not in keepa_data or len(keepa_data['products']) == 0:\n",
    "        raise ValueError(\"No products found\")\n",
    "    \n",
    "    product_data = keepa_data['products'][0]\n",
    "    df_prices = process_price_history(product_data)\n",
    "    \n",
    "    df_prices['CastleTopPattern'] = detect_castle_top_pattern(df_prices['OfferPrice'])\n",
    "    df_prices['FlatLine'] = detect_flat_lines(df_prices['OfferPrice'])\n",
    "    \n",
    "    if len(df_prices) >= 336:\n",
    "        df_prices['Drop7Days'] = df_prices['OfferPrice'].diff(periods=-336)\n",
    "        df_prices['LargeDrop7Days'] = (df_prices['Drop7Days'] >= 4) & (df_prices['Drop7Days'] < 7)\n",
    "        df_prices['ExtraLargeDrop7Days'] = df_prices['Drop7Days'] >= 7\n",
    "    else:\n",
    "        df_prices['Drop7Days'] = 0\n",
    "        df_prices['LargeDrop7Days'] = False\n",
    "        df_prices['ExtraLargeDrop7Days'] = False\n",
    "\n",
    "    if len(df_prices) >= 96:\n",
    "        df_prices['Drop2Days'] = df_prices['OfferPrice'].diff(periods=-96)\n",
    "        df_prices['LargeDrop2Days'] = df_prices['Drop2Days'] >= 4\n",
    "        df_prices['ExtraLargeDrop2Days'] = df_prices['Drop2Days'] >= 7\n",
    "    else:\n",
    "        df_prices['Drop2Days'] = 0\n",
    "        df_prices['LargeDrop2Days'] = False\n",
    "        df_prices['ExtraLargeDrop2Days'] = False\n",
    "    \n",
    "    df_prices['IsSeasonal'] = df_prices['Date'].apply(lambda x: x.month in [10, 11, 12])\n",
    "    df_prices['SeasonalDrop'] = df_prices['LargeDrop7Days'] & df_prices['IsSeasonal']\n",
    "    df_prices['NonSeasonalDrop'] = df_prices['LargeDrop7Days'] & ~df_prices['IsSeasonal']\n",
    "    \n",
    "    risk_factors = []\n",
    "    total_score, individual_scores = assign_score(df_prices, product_data, risk_factors)\n",
    "    response = {\n",
    "        \"total_score\": int(total_score),\n",
    "        \"individual_scores\": individual_scores,\n",
    "        \"risk_factors\": risk_factors\n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "def assign_score(df, product_data, risk_factors):\n",
    "    scores = {\n",
    "        'large_drop_7days': 20 if df['LargeDrop7Days'].sum() == 1 else 30 if 2 <= df['LargeDrop7Days'].sum() <= 4 else 40 if df['LargeDrop7Days'].sum() >= 5 else 0,\n",
    "        'large_drop_2days': 25 if df['LargeDrop2Days'].sum() == 1 else 35 if 2 <= df['LargeDrop2Days'].sum() <= 4 else 45 if df['LargeDrop2Days'].sum() >= 5 else 0,\n",
    "        'extra_large_drop_7days': 50 if df['ExtraLargeDrop7Days'].sum() == 1 else 55 if 2 <= df['ExtraLargeDrop7Days'].sum() <= 4 else 0,\n",
    "        'extra_large_drop_2days': 80 if df['ExtraLargeDrop2Days'].sum() == 1 else 85 if df['ExtraLargeDrop2Days'].sum() > 1 else 0,\n",
    "        'castle_top_pattern': 5 if df['CastleTopPattern'].sum() > 0 else 0,\n",
    "        'seasonal_drop': -15 if df['SeasonalDrop'].sum() > 0 else 0,\n",
    "        'non_seasonal_drop': 10 if df['NonSeasonalDrop'].sum() > 0 else 0\n",
    "    }\n",
    "\n",
    "    individual_scores = {key: val for key, val in scores.items() if val != 0}\n",
    "    total_score = sum(individual_scores.values())\n",
    "\n",
    "    for key, value in individual_scores.items():\n",
    "        risk_factors.append({\"factor\": key, \"severity\": value})\n",
    "\n",
    "    return min(total_score, 95), individual_scores\n",
    "\n",
    "# Example Usage\n",
    "asin = 'B00ABQD6OK'  # Replace with your ASIN\n",
    "result = analyze_data(asin)\n",
    "print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ASIN: B00ABQD6OK\n",
      "{\n",
      "  \"total_score\": 95,\n",
      "  \"individual_scores\": {\n",
      "    \"forward_quick_drops\": 35,\n",
      "    \"forward_extra_large_drops\": 20,\n",
      "    \"backward_quick_drops\": 35,\n",
      "    \"backward_extra_large_drops\": 20\n",
      "  },\n",
      "  \"risk_factors\": [\n",
      "    {\n",
      "      \"factor\": \"forward_quick_drops\",\n",
      "      \"severity\": 35\n",
      "    },\n",
      "    {\n",
      "      \"factor\": \"forward_extra_large_drops\",\n",
      "      \"severity\": 20\n",
      "    },\n",
      "    {\n",
      "      \"factor\": \"backward_quick_drops\",\n",
      "      \"severity\": 35\n",
      "    },\n",
      "    {\n",
      "      \"factor\": \"backward_extra_large_drops\",\n",
      "      \"severity\": 20\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Results for ASIN: B0D9YYCBSJ\n",
      "{\n",
      "  \"total_score\": 70,\n",
      "  \"individual_scores\": {\n",
      "    \"forward_quick_drops\": 35,\n",
      "    \"backward_quick_drops\": 35\n",
      "  },\n",
      "  \"risk_factors\": [\n",
      "    {\n",
      "      \"factor\": \"forward_quick_drops\",\n",
      "      \"severity\": 35\n",
      "    },\n",
      "    {\n",
      "      \"factor\": \"backward_quick_drops\",\n",
      "      \"severity\": 35\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Results for ASIN: B083Y69Z5C\n",
      "{\n",
      "  \"total_score\": 70,\n",
      "  \"individual_scores\": {\n",
      "    \"forward_quick_drops\": 35,\n",
      "    \"backward_quick_drops\": 35\n",
      "  },\n",
      "  \"risk_factors\": [\n",
      "    {\n",
      "      \"factor\": \"forward_quick_drops\",\n",
      "      \"severity\": 35\n",
      "    },\n",
      "    {\n",
      "      \"factor\": \"backward_quick_drops\",\n",
      "      \"severity\": 35\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Results for ASIN: B097TVQ1LY\n",
      "{\n",
      "  \"total_score\": 70,\n",
      "  \"individual_scores\": {\n",
      "    \"forward_quick_drops\": 35,\n",
      "    \"backward_quick_drops\": 35\n",
      "  },\n",
      "  \"risk_factors\": [\n",
      "    {\n",
      "      \"factor\": \"forward_quick_drops\",\n",
      "      \"severity\": 35\n",
      "    },\n",
      "    {\n",
      "      \"factor\": \"backward_quick_drops\",\n",
      "      \"severity\": 35\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "Summary of Results:\n",
      "[\n",
      "  {\n",
      "    \"ASIN\": \"B00ABQD6OK\",\n",
      "    \"Result\": {\n",
      "      \"total_score\": 95,\n",
      "      \"individual_scores\": {\n",
      "        \"forward_quick_drops\": 35,\n",
      "        \"forward_extra_large_drops\": 20,\n",
      "        \"backward_quick_drops\": 35,\n",
      "        \"backward_extra_large_drops\": 20\n",
      "      },\n",
      "      \"risk_factors\": [\n",
      "        {\n",
      "          \"factor\": \"forward_quick_drops\",\n",
      "          \"severity\": 35\n",
      "        },\n",
      "        {\n",
      "          \"factor\": \"forward_extra_large_drops\",\n",
      "          \"severity\": 20\n",
      "        },\n",
      "        {\n",
      "          \"factor\": \"backward_quick_drops\",\n",
      "          \"severity\": 35\n",
      "        },\n",
      "        {\n",
      "          \"factor\": \"backward_extra_large_drops\",\n",
      "          \"severity\": 20\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"ASIN\": \"B0D9YYCBSJ\",\n",
      "    \"Result\": {\n",
      "      \"total_score\": 70,\n",
      "      \"individual_scores\": {\n",
      "        \"forward_quick_drops\": 35,\n",
      "        \"backward_quick_drops\": 35\n",
      "      },\n",
      "      \"risk_factors\": [\n",
      "        {\n",
      "          \"factor\": \"forward_quick_drops\",\n",
      "          \"severity\": 35\n",
      "        },\n",
      "        {\n",
      "          \"factor\": \"backward_quick_drops\",\n",
      "          \"severity\": 35\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"ASIN\": \"B083Y69Z5C\",\n",
      "    \"Result\": {\n",
      "      \"total_score\": 70,\n",
      "      \"individual_scores\": {\n",
      "        \"forward_quick_drops\": 35,\n",
      "        \"backward_quick_drops\": 35\n",
      "      },\n",
      "      \"risk_factors\": [\n",
      "        {\n",
      "          \"factor\": \"forward_quick_drops\",\n",
      "          \"severity\": 35\n",
      "        },\n",
      "        {\n",
      "          \"factor\": \"backward_quick_drops\",\n",
      "          \"severity\": 35\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"ASIN\": \"B097TVQ1LY\",\n",
      "    \"Result\": {\n",
      "      \"total_score\": 70,\n",
      "      \"individual_scores\": {\n",
      "        \"forward_quick_drops\": 35,\n",
      "        \"backward_quick_drops\": 35\n",
      "      },\n",
      "      \"risk_factors\": [\n",
      "        {\n",
      "          \"factor\": \"forward_quick_drops\",\n",
      "          \"severity\": 35\n",
      "        },\n",
      "        {\n",
      "          \"factor\": \"backward_quick_drops\",\n",
      "          \"severity\": 35\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "\n",
    "# Keepa API credentials\n",
    "API_KEY = '1o6o8o0bd5ko9o6o635rs85jqj0no7g1upls93u8tbtt83sdt5gak24m593s6967'\n",
    "API_URL = 'https://api.keepa.com/product?key={}&domain=1&asin={}'\n",
    "\n",
    "# Fetch data from Keepa API\n",
    "def fetch_keepa_data(asin):\n",
    "    response = requests.get(API_URL.format(API_KEY, asin))\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"Failed to fetch data from Keepa API, status code: {response.status_code}\")\n",
    "    return response.json()\n",
    "\n",
    "# Process price history from Keepa data\n",
    "def process_price_history(product_data):\n",
    "    csv_data = product_data.get('csv', [])\n",
    "    offer_price_data = csv_data[3] if len(csv_data) > 3 and csv_data[3] is not None else []\n",
    "    if not offer_price_data:\n",
    "        raise ValueError(\"Offer price data is missing or not at the expected index.\")\n",
    "    \n",
    "    base_date = datetime(2011, 1, 1)\n",
    "    offer_price_dates = [base_date + timedelta(minutes=30 * i) for i in range(0, len(offer_price_data), 2)]\n",
    "    offer_price_values = [offer_price_data[i] for i in range(1, len(offer_price_data), 2)]\n",
    "    \n",
    "    df_prices = pd.DataFrame({\n",
    "        'Date': offer_price_dates,\n",
    "        'OfferPrice': offer_price_values\n",
    "    })\n",
    "    return df_prices\n",
    "\n",
    "# Detect patterns\n",
    "def detect_castle_top_pattern(series, window=336):\n",
    "    if len(series) < window:\n",
    "        return [0] * len(series)\n",
    "    pattern_detected = [0] * window\n",
    "    for i in range(window, len(series) - window):\n",
    "        is_castle_top = all(series[j] > series[j - 1] and series[j] > series[j + 1] for j in range(i - window // 2, i + window // 2, 2))\n",
    "        pattern_detected.append(int(is_castle_top))\n",
    "    pattern_detected.extend([0] * (len(series) - len(pattern_detected)))\n",
    "    return pattern_detected\n",
    "\n",
    "def detect_flat_lines(series, min_length=960, max_length=1440):\n",
    "    if len(series) < min_length:\n",
    "        return [0] * len(series)\n",
    "    flat_line = [0] * len(series)\n",
    "    count = 0\n",
    "    for i in range(1, len(series)):\n",
    "        if series[i] == series[i-1]:\n",
    "            count += 1\n",
    "        else:\n",
    "            if min_length <= count <= max_length:\n",
    "                for j in range(i - count, i):\n",
    "                    flat_line[j] = 1\n",
    "            count = 0\n",
    "    return flat_line\n",
    "\n",
    "# Analyze data\n",
    "def analyze_data(asin):\n",
    "    keepa_data = fetch_keepa_data(asin)\n",
    "    if 'products' not in keepa_data or len(keepa_data['products']) == 0:\n",
    "        raise ValueError(\"No products found\")\n",
    "    \n",
    "    product_data = keepa_data['products'][0]\n",
    "    df_prices = process_price_history(product_data)\n",
    "    \n",
    "    df_prices['CastleTopPattern'] = detect_castle_top_pattern(df_prices['OfferPrice'])\n",
    "    df_prices['FlatLine'] = detect_flat_lines(df_prices['OfferPrice'])\n",
    "    \n",
    "    if len(df_prices) >= 17520:  # 365 days * 48 half-hour intervals\n",
    "        df_prices['Drop365DaysForward'] = df_prices['OfferPrice'].diff(periods=-17520)\n",
    "        df_prices['Drop365DaysBackward'] = df_prices['OfferPrice'].diff(periods=17520)\n",
    "\n",
    "        df_prices['LargeDrop365DaysForward'] = (df_prices['Drop365DaysForward'] >= 4) & (df_prices['Drop365DaysForward'] < 7)\n",
    "        df_prices['ExtraLargeDrop365DaysForward'] = df_prices['Drop365DaysForward'] >= 7\n",
    "\n",
    "        df_prices['LargeDrop365DaysBackward'] = (df_prices['Drop365DaysBackward'] >= 4) & (df_prices['Drop365DaysBackward'] < 7)\n",
    "        df_prices['ExtraLargeDrop365DaysBackward'] = df_prices['Drop365DaysBackward'] >= 7\n",
    "    else:\n",
    "        df_prices['Drop365DaysForward'] = 0\n",
    "        df_prices['LargeDrop365DaysForward'] = False\n",
    "        df_prices['ExtraLargeDrop365DaysForward'] = False\n",
    "\n",
    "        df_prices['Drop365DaysBackward'] = 0\n",
    "        df_prices['LargeDrop365DaysBackward'] = False\n",
    "        df_prices['ExtraLargeDrop365DaysBackward'] = False\n",
    "    \n",
    "    df_prices['IsSeasonal'] = df_prices['Date'].apply(lambda x: x.month in [10, 11, 12])\n",
    "    df_prices['SeasonalDropForward'] = df_prices['LargeDrop365DaysForward'] & df_prices['IsSeasonal']\n",
    "    df_prices['NonSeasonalDropForward'] = df_prices['LargeDrop365DaysForward'] & ~df_prices['IsSeasonal']\n",
    "    df_prices['SeasonalDropBackward'] = df_prices['LargeDrop365DaysBackward'] & df_prices['IsSeasonal']\n",
    "    df_prices['NonSeasonalDropBackward'] = df_prices['LargeDrop365DaysBackward'] & ~df_prices['IsSeasonal']\n",
    "\n",
    "    df_prices['NewListing'] = (datetime.now() - df_prices['Date'].min()).days < 60\n",
    "    df_prices['ConsistentFlatLines'] = df_prices['FlatLine'].rolling(30).sum() >= 30\n",
    "    \n",
    "    risk_factors = []\n",
    "    total_score, individual_scores = assign_score(df_prices, product_data, risk_factors)\n",
    "    response = {\n",
    "        \"total_score\": int(total_score),\n",
    "        \"individual_scores\": individual_scores,\n",
    "        \"risk_factors\": risk_factors\n",
    "    }\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Assign scores\n",
    "def assign_score(df, product_data, risk_factors):\n",
    "    scores = {\n",
    "        'forward_quick_drops': 35 if df['LargeDrop365DaysForward'].sum() <= 4 else 0,\n",
    "        'forward_extra_large_drops': 20 if df['ExtraLargeDrop365DaysForward'].sum() > 0 else 0,\n",
    "        'backward_quick_drops': 35 if df['LargeDrop365DaysBackward'].sum() <= 4 else 0,\n",
    "        'backward_extra_large_drops': 20 if df['ExtraLargeDrop365DaysBackward'].sum() > 0 else 0,\n",
    "        'extra_long_flat_lines': 25 if df['ConsistentFlatLines'].sum() > 0 else 0,\n",
    "        'new_listing': -10 if df['NewListing'].sum() > 0 else 0,\n",
    "        'seasonal_drop_forward': -15 if df['SeasonalDropForward'].sum() > 0 else 0,\n",
    "        'non_seasonal_drop_forward': 10 if df['NonSeasonalDropForward'].sum() > 0 else 0,\n",
    "        'seasonal_drop_backward': -15 if df['SeasonalDropBackward'].sum() > 0 else 0,\n",
    "        'non_seasonal_drop_backward': 10 if df['NonSeasonalDropBackward'].sum() > 0 else 0\n",
    "    }\n",
    "\n",
    "    individual_scores = {key: val for key, val in scores.items() if val != 0}\n",
    "    total_score = sum(individual_scores.values())\n",
    "\n",
    "    for key, value in individual_scores.items():\n",
    "        risk_factors.append({\"factor\": key, \"severity\": value})\n",
    "\n",
    "    return min(total_score, 95), individual_scores\n",
    "\n",
    "# Test cases\n",
    "test_asins = ['B00ABQD6OK', 'B0D9YYCBSJ', 'B083Y69Z5C', 'B097TVQ1LY']  # Replace with actual ASINs for testing\n",
    "results = []\n",
    "# Iterate through each ASIN and test the function\n",
    "for asin in test_asins:\n",
    "    try:\n",
    "        # Call the analyze_data function\n",
    "        result = analyze_data(asin)\n",
    "        results.append({\"ASIN\": asin, \"Result\": result})\n",
    "        # Pretty-print the result for the current ASIN\n",
    "        print(f\"Results for ASIN: {asin}\")\n",
    "        print(json.dumps(result, indent=2))\n",
    "    except Exception as e:\n",
    "        # Append any errors encountered\n",
    "        results.append({\"ASIN\": asin, \"Error\": str(e)})\n",
    "        print(f\"Error for ASIN {asin}: {str(e)}\")\n",
    "\n",
    "# Final list of results\n",
    "print(\"Summary of Results:\")\n",
    "print(json.dumps(results, indent=2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
